[
{"updated": "2024-05-20T17:30:49.148Z", "metadata": {"contentType": null, "productName": "MongoDB Atlas", "tags": ["atlas", "docs"], "version": null}, "action": "created", "sourceName": "snooty-cloud-docs", "body": "# View Database Access History\n\n- This feature is not available for `M0` free clusters, `M2`, and `M5` clusters. To learn more, see Atlas M0 (Free Cluster), M2, and M5 Limits.\n\n- This feature is not supported on Serverless instances at this time. To learn more, see Serverless Instance Limitations.\n\n## Overview\n\nAtlas parses the MongoDB database logs to collect a list of authentication requests made against your clusters through the following methods:\n\n- `mongosh`\n\n- Compass\n\n- Drivers\n\nAuthentication requests made with API Keys through the Atlas Administration API are not logged.\n\nAtlas logs the following information for each authentication request within the last 7 days:\n\n<table>\n<tr>\n<th id=\"Field\">\nField\n\n</th>\n<th id=\"Description\">\nDescription\n\n</th>\n</tr>\n<tr>\n<td headers=\"Field\">\nTimestamp\n\n</td>\n<td headers=\"Description\">\nThe date and time of the authentication request.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Field\">\nUsername\n\n</td>\n<td headers=\"Description\">\nThe username associated with the database user who made the authentication request.\n\nFor LDAP usernames, the UI displays the resolved LDAP name. Hover over the name to see the full LDAP username.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Field\">\nIP Address\n\n</td>\n<td headers=\"Description\">\nThe IP address of the machine that sent the authentication request.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Field\">\nHost\n\n</td>\n<td headers=\"Description\">\nThe target server that processed the authentication request.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Field\">\nAuthentication Source\n\n</td>\n<td headers=\"Description\">\nThe database that the authentication request was made against. `admin` is the authentication source for SCRAM-SHA users and `$external` for LDAP users.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Field\">\nAuthentication Result\n\n</td>\n<td headers=\"Description\">\nThe success or failure of the authentication request. A reason code is displayed for the failed authentication requests.\n\n</td>\n</tr>\n</table>Authentication requests are pre-sorted by descending timestamp with 25 entries per page.\n\n### Logging Limitations\n\nIf a cluster experiences an activity spike and generates an extremely large quantity of log messages, Atlas may stop collecting and storing new logs for a period of time.\n\nLog analysis rate limits apply only to the Performance Advisor UI, the Query Insights UI, the Access Tracking UI, and the Atlas Search Query Analytics UI. Downloadable log files are always complete.\n\nIf authentication requests occur during a period when logs are not collected, they will not appear in the database access history.\n\n## Required Access\n\nTo view database access history, you must have `Project Owner` or `Organization Owner` access to Atlas.\n\n## Procedure\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo return the access logs for a cluster using the Atlas CLI, run the following command:\n\n```sh\n\natlas accessLogs list [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas accessLogs list.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas Administration API\">\n\nTo view the database access history using the API, see Access Tracking.\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nUse the following procedure to view your database access history using the Atlas UI:\n\n### Navigate to the Clusters page for your project.\n\n- If it is not already displayed, select the organization that contains your desired project from the  Organizations menu in the navigation bar.\n\n- If it is not already displayed, select your desired project from the Projects menu in the navigation bar.\n\n- If the Clusters page is not already displayed, click Database in the sidebar.\n\n### View the cluster's database access history.\n\n- On the cluster card, click .\n\n- Select View Database Access History.\n\nor\n\n- Click the cluster name.\n\n- Click .\n\n- Select View Database Access History.\n\n</Tab>\n\n</Tabs>\n\n", "url": "https://mongodb.com/docs/atlas/access-tracking/", "format": "md", "title": "View Database Access History"},
{"updated": "2024-05-20T17:30:49.148Z", "metadata": {"contentType": null, "productName": "MongoDB Atlas", "tags": ["atlas", "docs"], "version": null}, "action": "created", "sourceName": "snooty-cloud-docs", "body": "# Manage Organization Teams\n\nYou can create teams at the organization level and add teams to projects to grant project access roles to multiple users. Add any number of organization users to a team.\n\nGrant a team roles for specific projects. All members of a team share the same project access. Organization users can belong to multiple teams. To add teams to a project or edit team roles, see Manage Access to a Project.\n\n## Required Access\n\nTo perform any of the following actions, you must have `Organization Owner` access to Atlas.\n\n## Create a Team\n\nAtlas limits the number of users to a maximum of 100 teams per project and a maximum of 250 teams per organization.\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo create one team in your organization using the Atlas CLI, run the following command:\n\n```sh\n\natlas teams create <name> [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas teams create.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\nTo add users to your team, see Add Team Members.\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo create a team using the Atlas UI:\n\n### Navigate to the Access Manager page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\n\n### Click Create Team.\n\n### Enter a name for the team in the Name Your Team box.\n\nThe name must be unique within an organization.\n\n### Add team members.\n\nTo add existing organization users to the team, click in the Add Members box and either start typing their Cloud Manager username or click on the name of a user that appears in the combo box.\n\n### Click Create Team.\n\n</Tab>\n\n</Tabs>\n\n## View Teams\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo list all teams in your organization using the Atlas CLI, run the following command:\n\n```sh\n\natlas teams list [options]\n\n```\n\nTo return the details for the team you specify using the Atlas CLI, run the following command:\n\n```sh\n\natlas teams describe [options]\n\n```\n\nTo learn more about the syntax and parameters for the previous commands, see the Atlas CLI documentation for atlas teams list and atlas teams describe.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo view your teams using the Atlas UI:\n\n### Navigate to the Access Manager page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\n\n### Click the Teams tab.\n\nYour teams display.\n\n</Tab>\n\n</Tabs>\n\n## Add Team Members\n\nAtlas limits Atlas user membership to a maximum of 250 Atlas users per team.\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo add one user to the team you specify using the Atlas CLI, run the following command:\n\n```sh\n\natlas teams users add <userId>... [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas teams users add.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo add team members using the Atlas UI:\n\n### Navigate to the Access Manager page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\n\n### Click the Teams tab.\n\n### Click the name of the team you want to modify.\n\n### Add members to the team.\n\n- Click Add Members.\n\n- Type the name or email of the user from the combo box.\n\n  You can add users that are part of the organization or users that have been sent an invitation to join the organization.\n\n- Click Add Members.\n\n</Tab>\n\n</Tabs>\n\n## Remove Team Members\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo delete one user from the team you specify using the Atlas CLI, run the following command:\n\n```sh\n\natlas teams users delete <userId> [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas teams users delete.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo remove team members using the Atlas UI:\n\n### Navigate to the Access Manager page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\n\n### Click the Teams tab.\n\n### Click the name of the team you want to modify.\n\n### Remove members from the team.\n\nClick  to the right of the user you want to remove from a team.\n\nRemoving a member from the team removes the user's project assignments granted by the team membership.\n\nIf a user is assigned to a project through both a team and individual assignment, removing the user from a team does not remove the user's assignment to that project.\n\n</Tab>\n\n</Tabs>\n\n## Rename a Team\n\nYou can't rename a team using the Atlas CLI.\n\n### Navigate to the Access Manager page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\n\n### Click the Teams tab.\n\n### Rename the team.\n\nFor the team you want to rename:\n\n- Click the ellipsis (`...`) button under the Actions column.\n\n- Click Rename Team.\n\n- Enter a new name for the team.\n\n  The team name must be unique within the organization.\n\n- Click Rename Team.\n\n## Delete a Team\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo delete one team from your organization using the Atlas CLI, run the following command:\n\n```sh\n\natlas teams delete <teamId> [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas teams delete.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo delete a team using the Atlas UI:\n\n### Navigate to the Access Manager page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\n\n### Click the Teams tab.\n\n### Delete the team.\n\nFor the team you want to delete:\n\n- Click the ellipsis (`...`) button under the Actions column.\n\n- Click Delete Team.\n\n- Confirm that you wish to proceed with team deletion.\n\n  For users belonging to the team, deleting a team removes the users' project assignments granted by that team membership.\n\n</Tab>\n\n</Tabs>\n\n## Next Steps\n\nFor the organization users in a team to have access to a project, you must add the team to the project. To add teams to a project or edit team roles, see Manage Access to a Project.\n\n", "url": "https://mongodb.com/docs/atlas/access/manage-teams-in-orgs/", "format": "md", "title": "Manage Organization Teams"},
{"updated": "2024-05-20T17:30:49.148Z", "metadata": {"contentType": null, "productName": "MongoDB Atlas", "tags": ["atlas", "docs"], "version": null}, "action": "created", "sourceName": "snooty-cloud-docs", "body": "# Manage Organizations\n\nIn the organizations and projects hierarchy, an organization can contain multiple projects (previously referred to as groups). Under this structure:\n\n- Billing happens at the organization level while preserving visibility into usage in each project.\n\n- You can view all projects within an organization.\n\n- You can use teams to bulk assign organization users to projects within the organization.\n\nIf you need to scale beyond the existing project limits, you can create multiple organizations.\n\n## Create an Organization\n\nWhen you create an organization, you are added as an `Organization Owner` for the organization.\n\n### View all of your organizations.\n\n- Expand the Organizations menu in the navigation bar.\n\n- Click View All Organizations.\n\n### Click New Organization.\n\n### Enter the name for your organization.\n\nDon't include sensitive information in your organization name.\n\n### Select Atlas and click Next.\n\nYou have the option of adding a new Cloud Manager organization or a new Atlas organization. For more information on Cloud Manager see the documentation.\n\n### Add members.\n\n- For existing Atlas users, enter their username. Usually, this is the email the person used to register.\n\n- For new Atlas users, enter their email address to send an invitation.\n\n### Specify the access for the members.\n\n### (Optional) Disable the IP access list requirement for the Atlas Administration API.\n\nWhen you create a new organization with the Atlas UI, Atlas requires IP access lists for the Atlas Administration API by default. If you require an IP access list, your Atlas Administration API keys can make API (Application Programming Interface) requests only from the location-based IP or CIDR (Classless Inter-Domain Routing) addresses that you specify in the IP access list.\n\nTo disable the IP access list requirement and allow your Atlas Administration API keys to make requests from any address on the internet, toggle Require IP Access List for the Atlas Administration API to OFF.\n\nTo learn more, see Optional: Require an IP Access List for the Atlas Administration API.\n\n### Click Create Organization.\n\n## View Organizations\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo list all organizations using the Atlas CLI, run the following command:\n\n```sh\n\natlas organizations list [options]\n\n```\n\nTo return the details for the organization you specify using the Atlas CLI, run the following command:\n\n```sh\n\natlas organizations describe <ID> [options]\n\n```\n\nTo learn more about the syntax and parameters for the previous commands, see the Atlas CLI documentation for atlas organizations list and atlas organizations describe.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\n### Expand the Organizations menu in the navigation bar.\n\n### Click View All Organizations.\n\n</Tab>\n\n</Tabs>\n\n## Leave an Organization\n\nTo leave an organization, at least another user must exist as an Owner for the organization.\n\n### View all of your organizations.\n\n- Expand the Organizations menu in the navigation bar.\n\n- Click View All Organizations.\n\n### Leave organization.\n\nFor the organization you wish to leave, click its Leave button to bring up the Leave Organization dialog.\n\n### Click Leave Organization in the Leave Organization dialog.\n\n## Rename an Organization\n\nYou must have the `Organization Owner` role for an organization to rename it.\n\n### Navigate to the Settings page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click the Organization Settings icon next to the Organizations menu.\n\n### Click  next to the organization name.\n\n### Enter the new name for the organization.\n\n### Click Save.\n\n## Delete an Organization\n\nTo delete an organization, you must have `Organization Owner` role for the organization.\n\nYou can't delete an organization that has active projects. You must delete the organization's projects before you can delete the organization.\n\nYou can't delete an organization with outstanding payments. To learn more, see Troubleshoot Invoices and Payments.\n\nIf you have a Backup Compliance Policy enabled, you can't delete a project if any snapshots exists. If you can't remove all projects, you can't delete the organization.\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo delete an organization using the Atlas CLI, run the following command:\n\n```sh\n\natlas organizations delete <ID> [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas organizations delete.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\n### Navigate to the Settings page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click the Organization Settings icon next to the Organizations menu.\n\n### In the General Settings tab, click Delete.\n\nThis displays the Delete Organization dialog.\n\n### Click Delete Organization to confirm.\n\n</Tab>\n\n</Tabs>\n\n", "url": "https://mongodb.com/docs/atlas/access/orgs-create-view-edit-delete/", "format": "md", "title": "Manage Organizations"},
{"updated": "2024-05-20T17:30:49.148Z", "metadata": {"contentType": null, "productName": "MongoDB Atlas", "tags": ["atlas", "docs"], "version": null}, "action": "created", "sourceName": "snooty-cloud-docs", "body": "# Alert Basics\n\nAtlas provides built-in tools, alerts, charts, integrations, and logs to help you monitor your clusters. Atlas provides alerts to help you monitor your clusters and improve performance in the following ways:\n\n1. A variety of conditions can trigger an alert.\n\n2. You can configure alerts settings based on specific conditions for your databases, users, accounts, and more.\n\n3. When you resolve alerts, you can fix the immediate problem, implement a long-term solution, and monitor your progress.\n\nAtlas issues alerts for the database and server conditions configured in your alert settings. When a condition triggers an alert, Atlas displays a warning symbol on the cluster and sends alert notifications. Your alert settings determine the notification methods. Atlas continues sending notifications at regular intervals until the condition resolves or you delete or disable the alert.\n\n## Useful Metrics and Alert Conditions\n\nWhen you configure alerts, you specify alert conditions and thresholds. Review the possible alert conditions for which you can trigger alerts related to your clusters.\n\n`M0` free clusters and `M2/M5` shared clusters only trigger alerts related to the metrics supported by those clusters. See Atlas M0 (Free Cluster), M2, and M5 Limits for complete documentation on `M0/M2/M5` alert and metric limitations.\n\nConsistently monitor metrics to help ensure efficient clusters.\n\n### Tickets Available\n\nThese alert conditions help you monitor the number of concurrent read or write operations that can occur. When all tickets are claimed, operations must wait and enter the queue.\n\nYou can view these metrics on the Tickets Available chart, accessed through cluster monitoring.\n\nTo learn more, see the Tickets Available alert conditions.\n\n### Queues\n\nThese alert conditions measure operations waiting on locks.\n\nYou can view these metrics on the Queues chart, accessed through cluster monitoring.\n\nTo learn more, see the Queues alert conditions.\n\n### CPU Steal\n\nAWS EC2 clusters that support Burstable Performance might experience CPU steal when using shared CPU cores. This alert condition measures the percentage by which the CPU usage exceeds the guaranteed baseline CPU credit accumulation rate.\n\nCPU credits are units of CPU utilization that you accumulate. The credits accumulate at a constant rate to provide a guaranteed level of performance. These credits can be used for additional CPU performance. When the credit balance is exhausted, only the guaranteed baseline of CPU performance is provided, and the amount of excess is shown as steal percent.\n\nYou can view CPU usage on the Normalized System CPU chart, accessed through cluster monitoring.\n\nTo learn more, see the `System: CPU (Steal) % is` alert condition.\n\n### Query Targeting\n\nProperly configured indexes can significantly improve query performance. These alert conditions help identify inefficient queries. Too many indexes can impact write performance.\n\nYou can view these metrics on the Query Targeting chart, accessed through cluster monitoring.\n\nTo learn more, see the Query Targeting alert conditions.\n\n### Connection Limits\n\nEach Atlas instance has a connection limit. These alert conditions help you proactively address scaling needs or potential issues related to connection availability.\n\nYou can view these metrics on the Connections chart, accessed through cluster monitoring.\n\nTo learn more, see the Connection alert conditions.\n\n## Configure Alerts\n\nTo set which conditions trigger alerts and how users are notified, Configure Alert Settings. You can configure alerts at the organization or project level. Atlas provides default alerts at the project level. You can clone existing alerts and configure maintenance window alerts.\n\nExperiment with alert condition values based on your specific requirements. Periodically reassess these values for optimal performance.\n\n### Tickets Available\n\nConfigure the alert settings to send an alert if these metrics drop below 30 for at least a few minutes. You want to avoid false positives triggered by relatively harmless short-term drops, but catch issues when these metrics stay low for a while.\n\nTo configure these alert conditions, see Configure Alert Settings.\n\n### Queues\n\nConfigure the alert settings to send an alert if these metrics rise above 100 for a minute. You want to avoid false positives triggered by relatively harmless short-term spikes, but catch issues when these metrics stay elevated for a while.\n\nTo configure these alert conditions, see Configure Alert Settings.\n\n### CPU Steal\n\nConfigure the alert settings to send an alert if this metric rises above 10%.\n\nTo configure this alert condition, see Configure Alert Settings.\n\n### Query Targeting\n\nConfigure the alert settings to send an alert if this metric rises above 50 or 100.\n\nTo configure these alert conditions, see Configure Alert Settings.\n\n### Connection Limits\n\nConfigure the alert settings to send an alert if the Connection % of the configured limit rises above 80% or 90%.\n\nTo configure these alert conditions, see Configure Alert Settings.\n\n## Resolve Alerts\n\nWhen a condition triggers an alert, Atlas displays a warning symbol on the cluster and sends alert notifications. Resolve these alerts and work to prevent alert conditions from occurring in the future. To learn how to fix the immediate problem, implement a long-term solution, and monitor your progress, see Resolve Alerts.\n\n### Tickets Available\n\nTickets Available alerts can help you detect queries that took a little longer than expected due to load.\n\nIncreasing your instance size, or sometimes disk speed, can help these metrics.\n\n### Queues\n\nQueues alerts can help you detect queries that took a little longer than expected due to load.\n\nIncreasing your instance size, or sometimes disk speed, can help these metrics.\n\n### CPU Steal\n\nThe `System: CPU (Steal) % is` alert occurs when the CPU usage exceeds the guaranteed baseline CPU credit accumulation rate by the specified threshold.\n\nTo learn more, see Fix CPU Usage Issues.\n\n### Query Targeting\n\nQuery Targeting alerts often indicate inefficient queries.\n\nTo learn more, see Fix Query Issues.\n\n### Connection Limits\n\nConnection alerts typically occur when the maximum number of allowable connections to a MongoDB process has been exceeded. Once the limit is exceeded, no new connections can be opened until the number of open connections drops down below the limit.\n\nTo learn more, see Fix Connection Issues.\n\n## Alerts Workflow\n\nWhen an alert condition is met, the alert lifecycle begins.\n\nTo learn more, see the Alerts Workflow.\n\n", "url": "https://mongodb.com/docs/atlas/alert-basics/", "format": "md", "title": "Alert Basics"},
{"updated": "2024-05-20T17:30:49.148Z", "metadata": {"contentType": null, "productName": "MongoDB Atlas", "tags": ["atlas", "docs"], "version": null}, "action": "created", "sourceName": "snooty-cloud-docs", "body": "# Resolve Alerts\n\nAtlas issues alerts for the database and server conditions configured in your alert settings. When a condition triggers an alert, Atlas displays a warning symbol on the cluster and sends alert notifications. Your alert settings determine the notification methods. Atlas continues sending notifications at regular intervals until the condition resolves or you delete or disable the alert. You should fix the immediate problem, implement a long-term solution, and view metrics to monitor your progress.\n\nIf you integrate with VictorOps, OpsGenie, or DataDog, you can recieve informational alerts from these third-party monitoring services in Atlas. However, you must resolve these alerts within each external service.\n\n<Tabs>\n\n<Tab name=\"Organization Alerts\">\n\n</Tab>\n\n<Tab name=\"Project Alerts\">\n\n</Tab>\n\n</Tabs>\n\n## View Alerts\n\n<Tabs>\n\n<Tab name=\"Organization Alerts\">\n\nYou can view all alerts, alert settings, and deleted alerts on the Organization Alerts page. To learn more, see Alerts Workflow.\n\nTo view all open alerts:\n\n### Navigate to the Alerts page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Alerts in the sidebar.\n\n### If it is not already displayed, click the All Alerts tab.\n\n</Tab>\n\n<Tab name=\"Project Alerts\">\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo list all alerts for the specified Atlas project using the Atlas CLI, run the following command:\n\n```sh\n\natlas alerts list [options]\n\n```\n\nTo return the details for one alert in the project you specify using the Atlas CLI, run the following command:\n\n```sh\n\natlas alerts describe <alertId> [options]\n\n```\n\nTo learn more about the syntax and parameters for the previous commands, see the Atlas CLI documentation for atlas alerts list and atlas alerts describe.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nYou can view open alerts, closed alerts, and alert settings on the Project Alerts page. Atlas sends notifications for all alerts that appear on the Open tab. To learn more, see Alerts Workflow.\n\nTo view all open alerts using the Atlas UI:\n\n### Navigate to the Alerts page for your project.\n\n- If it is not already displayed, select the organization that contains your desired project from the  Organizations menu in the navigation bar.\n\n- If it is not already displayed, select your desired project from the Projects menu in the navigation bar.\n\n- Click the  Project Alerts icon in the navigation bar, or click Alerts in the sidebar.\n\n### If it is not already displayed, click the Open Alerts tab.\n\n</Tab>\n\n</Tabs>\n\n</Tab>\n\n</Tabs>\n\n## Acknowledge Alerts\n\n<Tabs>\n\n<Tab name=\"Organization Alerts\">\n\nTo acknowledge alerts:\n\n### Navigate to the Alerts page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Alerts in the sidebar.\n\n### Select the alert you want to acknowledge, then click Mark Acknowledge.\n\nIf an alert uses PagerDuty for alert notifications, you can acknowledge the alert only on your PagerDuty dashboard.\n\n</Tab>\n\n<Tab name=\"Project Alerts\">\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo acknowledge one alert for the specified project using the Atlas CLI, run the following command:\n\n```sh\n\natlas alerts acknowledge <alertId> [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas alerts acknowledge.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo acknowledge alerts using the Atlas UI:\n\n### Navigate to the Alerts page for your project.\n\n- If it is not already displayed, select the organization that contains your desired project from the  Organizations menu in the navigation bar.\n\n- If it is not already displayed, select your desired project from the Projects menu in the navigation bar.\n\n- Click the  Project Alerts icon in the navigation bar, or click Alerts in the sidebar.\n\n### Locate the alert you want to acknowledge, then click Acknowledge.\n\nIf an alert uses PagerDuty for alert notifications, you can acknowledge the alert only on your PagerDuty dashboard.\n\n</Tab>\n\n</Tabs>\n\n</Tab>\n\n</Tabs>\n\nWhen you acknowledge an alert, Atlas sends no further notifications until either the acknowledgement period ends, you resolve the alert condition, or you unacknowledge the alert. If an alert condition ends during an acknowledgment period, Atlas sends a notification.\n\n## Unacknowledge Alerts\n\nYou can unacknowledge an alert that you previously acknowledged. After you unacknowledge an active alert, Atlas resumes sending notifications at regular intervals until the condition resolves or you delete, disable, or re-acknowledge the alert.\n\n<Tabs>\n\n<Tab name=\"Organization Alerts\">\n\nTo unacknowledge alerts:\n\n### Navigate to the Alerts page for your organization.\n\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\n\n- Click Alerts in the sidebar.\n\n### Select the alert you want to acknowledge, then click Unacknowledge on the right side of the alert.\n\nIf an alert uses PagerDuty for alert notifications, you can acknowledge the alert only on your PagerDuty dashboard.\n\n</Tab>\n\n<Tab name=\"Project Alerts\">\n\n<Tabs>\n\n<Tab name=\"Atlas CLI\">\n\nTo unacknowledge one alert for the specified project using the Atlas CLI, run the following command:\n\n```sh\n\natlas alerts unacknowledge <alertId> [options]\n\n```\n\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas alerts unacknowledge.\n\n- Install the Atlas CLI\n\n- Connect to the Atlas CLI\n\n</Tab>\n\n<Tab name=\"Atlas UI\">\n\nTo unacknowledge alerts using the Atlas UI:\n\n### Navigate to the Alerts page for your project.\n\n- If it is not already displayed, select the organization that contains your desired project from the  Organizations menu in the navigation bar.\n\n- If it is not already displayed, select your desired project from the Projects menu in the navigation bar.\n\n- Click the  Project Alerts icon in the navigation bar, or click Alerts in the sidebar.\n\n### Locate the alert you want to acknowledge, then click Unacknowledge on the right side of the alert.\n\nIf an alert uses PagerDuty for alert notifications, you can acknowledge the alert only on your PagerDuty dashboard.\n\n</Tab>\n\n</Tabs>\n\n</Tab>\n\n</Tabs>\n\n## Increase Cluster Capacity\n\nTo resolve an alert by increasing your cluster's capacity, see Modify a Cluster.\n\n## View All Activity\n\nTo view and filter the activity feed for an organization or project, see View the Activity Feed.\n\n## Retrieve the Activity Feed\n\n<Tabs>\n\n<Tab name=\"Organization Alerts\">\n\nYou can retrieve events for an organization using the get all API (Application Programming Interface) resource.\n\n</Tab>\n\n<Tab name=\"Project Alerts\">\n\nYou can retrieve events for a project using the get all API (Application Programming Interface) resource.\n\n</Tab>\n\n</Tabs>\n\n## Resolutions for Specific Alerts\n\nThe following sections describe Atlas\nalert conditions and suggest steps for resolving them.\n\n<table>\n<tr>\n<th id=\"Alert%20Type\">\nAlert Type\n\n</th>\n<th id=\"Description\">\nDescription\n\n</th>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nAtlas Search Alerts\n\n</td>\n<td headers=\"Description\">\nAmount of CPU and memory used by Atlas Search processes reach a specified threshold.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nConnection Alerts\n\n</td>\n<td headers=\"Description\">\nNumber of connections to a MongoDB process exceeds the allowable maximum.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nDisk Space % Used Alerts\n\n</td>\n<td headers=\"Description\">\nPercentage of used disk space on a partition reaches a specified threshold.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nQuery Targeting Alerts\n\n</td>\n<td headers=\"Description\">\nIndicates inefficient queries.\n\nThe change streams cursors that the Atlas Search process (`mongot`) uses to keep Atlas Search indexes updated can contribute to the query targeting ratio and trigger query targeting alerts if the ratio is high.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nReplica Set Has No Primary\n\n</td>\n<td headers=\"Description\">\nNo primary is detected in replica set.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nReplication Oplog Alerts\n\n</td>\n<td headers=\"Description\">\nAmount of oplog data generated on a primary cluster member is larger than the cluster's configured oplog size.\n\n</td>\n</tr>\n<tr>\n<td headers=\"Alert%20Type\">\nSystem CPU Usage Alerts\n\n</td>\n<td headers=\"Description\">\nCPU usage of the MongoDB process reaches a specified threshold.\n\n</td>\n</tr>\n</table>\n\n", "url": "https://mongodb.com/docs/atlas/alert-resolutions/", "format": "md", "title": "Resolve Alerts"},
{"updated": "2024-05-20T17:32:10.812Z", "metadata": {"contentType": null, "productName": "PyMongo", "tags": ["docs", "driver", "python", "pymongo"], "version": "v4.7 (current)"}, "action": "created", "sourceName": "snooty-pymongo", "body": "# Aggregation Tutorials\n\n## Overview\n\nAggregation tutorials provide detailed explanations of common aggregation tasks in a step-by-step format. The tutorials are adapted from examples in the Practical MongoDB Aggregations book by Paul Done.\n\nEach tutorial includes the following sections:\n\n- **Introduction**, which describes the purpose and common use cases of the aggregation type. This section also describes the example and desired outcome that the tutorial demonstrates.\n\n- **Before You Get Started**, which describes the necessary databases, collections, and sample data that you must have before building the aggregation pipeline and performing the aggregation.\n\n- **Tutorial**, which describes how to build and run the aggregation pipeline. This section describes each stage of the completed aggregation tutorial, and then explains how to run and interpret the output of the aggregation.\n\nAt the end of each aggregation tutorial, you can find a link to a fully runnable Python code file that you can run in your environment.\n\n## Aggregation Template App\n\nBefore you begin following an aggregation tutorial, you must set up a new Python app. You can use this app to connect to a MongoDB deployment, insert sample data into MongoDB, and run the aggregation pipeline in each tutorial.\n\nTo learn how to install the driver and connect to MongoDB, see Get Started with PyMongo\n\nOnce you install the driver, create a file called `agg_tutorial.py`. Paste the following code in this file to create an app template for the aggregation tutorials:\n\n```python\nfrom pymongo import MongoClient\n\n# Replace the placeholder with your connection string.\nuri = \"<connection string>\"\nclient = MongoClient(uri)\n\ntry:\n    agg_db = client[\"agg_tutorials_db\"]\n\n    # Get a reference to relevant collections.\n    # ... some_coll =\n    # ... another_coll =\n\n    # Delete any existing documents in collections.\n    # ... some_coll.delete_many({})\n\n    # Insert sample data into the collection or collections.\n    # ... some_data = [...]\n\n    # ... some_coll.insert_many(some_data)\n\n    # Create an empty pipeline array.\n    pipeline = []\n\n    # Add code to create pipeline stages.\n    # ... pipeline.append({...})\n\n    # Run the aggregation.\n    # ... aggregation_result = ...\n\n    # Print the aggregation results.\n    for document in aggregation_result:\n        print(document)\n\nfinally:\n    client.close()\n\n```\n\nIn the preceding code, read the code comments to find the sections of the code that you must modify for the tutorial you are following.\n\nIf you attempt to run the code without making any changes, you will encounter a connection error.\n\nFor every tutorial, you must replace the connection string placeholder with your deployment's connection string. To learn how to locate your deployment's connection string, see Create a Connection String.\n\nFor example, if your connection string is `\"mongodb+srv://mongodb-example:27017\"`, your connection string assignment resembles the following:\n\n```python\nuri = \"mongodb+srv://mongodb-example:27017\";\n```\n\nTo run the completed file after you modify the template for a tutorial, run the following command in your shell:\n\n```bash\npython3 agg_tutorial.py\n```\n\n## Available Tutorials\n\n- Filtered Subset\n\n- Group and Total\n\n- Unpack Arrays and Group\n\n- One-to-One Join\n\n- Multi-Field Join\n\n", "url": "https://mongodb.com/docs/languages/python/pymongo-driver/current/aggregation/aggregation-tutorials/", "format": "md", "title": "Aggregation Tutorials"},
{"updated": "2024-05-20T17:32:10.812Z", "metadata": {"contentType": null, "productName": "PyMongo", "tags": ["docs", "driver", "python", "pymongo"], "version": "v4.7 (current)"}, "action": "created", "sourceName": "snooty-pymongo", "body": "# Specialized Data Formats\n\n## Overview\n\nYou can use several types of specialized data formats in your PyMongo application. To learn how to work with these data formats, see the following sections:\n\n- Learn how to encode and decode custom types in the Custom Types guide.\n\n- Learn how to work with Python `datetime` objects in PyMongo in the Dates and Times guide.\n\n- Learn about UUIDs and how to maintain cross-language compatibility while working with them in the Universally Unique IDs (UUIDs) guide.\n\n", "url": "https://mongodb.com/docs/languages/python/pymongo-driver/current/data-formats/", "format": "md", "title": "Specialized Data Formats"},
{"updated": "2024-05-20T17:32:10.812Z", "metadata": {"contentType": null, "productName": "PyMongo", "tags": ["docs", "driver", "python", "pymongo"], "version": "v4.7 (current)"}, "action": "created", "sourceName": "snooty-pymongo", "body": "# Create a MongoDB Deployment\n\nYou can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\n\n## Create a Free MongoDB deployment on Atlas\n\nComplete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\n\n## Save your Credentials\n\nAfter you create your database user, save that user's username and password to a safe location for use in an upcoming step.\n\nAfter you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\n\nIf you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\n\n", "url": "https://mongodb.com/docs/languages/python/pymongo-driver/current/get-started/create-a-deployment/", "format": "md", "title": "Create a MongoDB Deployment"},
{"updated": "2024-05-20T17:32:10.812Z", "metadata": {"contentType": null, "productName": "PyMongo", "tags": ["docs", "driver", "python", "pymongo"], "version": "v4.7 (current)"}, "action": "created", "sourceName": "snooty-pymongo", "body": "# Compound Indexes\n\n## Overview\n\nCompound indexes hold references to multiple fields within a collection's documents, improving query and sort performance.\n\n### Sample Data\n\nThe examples in this guide use the `sample_mflix.movies` collection from the Atlas sample datasets. To learn how to create a free MongoDB Atlas cluster and load the sample datasets, see the Get Started with PyMongo.\n\n## Create a Compound Index\n\nThe following example creates a compound index on the `type` and `genre` fields:\n\n```python\nmovies.create_index([(\"type\", pymongo.ASCENDING), (\"genre\", pymongo.ASCENDING)])\n```\n\nThe following is an example of a query that uses the index created in the preceding code example:\n\n```python\nquery = { \"type\": \"movie\", \"genre\": \"Drama\" }\nsort = [(\"type\", pymongo.ASCENDING), (\"genre\", pymongo.ASCENDING)]\n\ncursor = movies.find(query).sort(sort)\n```\n\nFor more information, see Compound Indexes in the MongoDB Server manual.\n\n", "url": "https://mongodb.com/docs/languages/python/pymongo-driver/current/indexes/compound-index/", "format": "md", "title": "Compound Indexes"},
{"updated": "2024-05-20T17:32:10.812Z", "metadata": {"contentType": null, "productName": "PyMongo", "tags": ["docs", "driver", "python", "pymongo"], "version": "v4.7 (current)"}, "action": "created", "sourceName": "snooty-pymongo", "body": "# Previous Versions\n\nThe following links direct you to documentation for previous versions of PyMongo.\n\n- Version 4.6\n\n- Version 4.5\n\n- Version 4.4\n\n- Version 4.3\n\n- Version 4.2\n\n- Version 4.1\n\n- Version 4.0\n\n", "url": "https://mongodb.com/docs/languages/python/pymongo-driver/current/previous-versions/", "format": "md", "title": "Previous Versions"},
{"updated": "2024-05-20T17:31:07.735Z", "metadata": {"contentType": null, "productName": "MongoDB Server", "tags": ["docs", "manual"], "version": "v7.0 (current)"}, "action": "created", "sourceName": "snooty-docs", "body": "# About MongoDB Documentation\n\nThe MongoDB Manual contains comprehensive documentation on MongoDB. This page describes the manual's licensing, editions, and versions, and describes how to make a change request and how to contribute to the manual.\n\n## License\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License\n\n\u00a9 MongoDB, Inc. 2008-2022\n\n## Man Pages\n\nIn addition to the MongoDB Manual, you can access the MongoDB Man Pages, which are also distributed with the official MongoDB Packages.\n\n## Version and Revisions\n\nThis version of the manual reflects version 7.0 of MongoDB.\n\nSee the MongoDB Documentation Project Page for an overview of all editions and output formats of the MongoDB Manual. You can see the full revision history and track ongoing improvements and additions for all versions of the manual from its GitHub repository.\n\nThe most up-to-date, current, and stable version of the manual is always available at \"https://www.mongodb.com/docs/manual/\".\n\n## Report an Issue or Make a Change Request\n\nTo report an issue with this manual or to make a change request, file a ticket at the MongoDB DOCS Project on Jira.\n\n## Contribute to the Documentation\n\nThe entire documentation source for this manual is available in the mongodb/docs repository, which is one of the MongoDB project repositories on GitHub.\n\nTo contribute to the documentation, you can open a GitHub account, fork the mongodb/docs repository, make a change, and issue a pull request.\n\nIn order for the documentation team to accept your change, you must complete the MongoDB Contributor Agreement.\n\nYou can clone the repository by issuing the following command at your system shell:\n\n```bash\ngit clone git://github.com/mongodb/docs.git\n```\n\n### About the Documentation Process\n\nThe MongoDB Manual uses Sphinx, a sophisticated documentation engine built upon Python Docutils. The original reStructured Text files, as well as all necessary Sphinx extensions and build tools, are available in the same repository as the documentation.\n\nFor more information on the MongoDB documentation process, see the Meta Documentation.\n\nIf you have any questions, please feel free to open a Jira Case.\n\n", "url": "https://mongodb.com/docs/manual/about/", "format": "md", "title": "About MongoDB Documentation"},
{"updated": "2024-05-20T17:31:07.735Z", "metadata": {"contentType": null, "productName": "MongoDB Server", "tags": ["docs", "manual"], "version": "v7.0 (current)"}, "action": "created", "sourceName": "snooty-docs", "body": "# Administration\n\nThe administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB.\n\n", "url": "https://mongodb.com/docs/manual/administration/", "format": "md", "title": "Administration"},
{"updated": "2024-05-20T17:31:07.735Z", "metadata": {"contentType": null, "productName": "MongoDB Server", "tags": ["docs", "manual"], "version": "v7.0 (current)"}, "action": "created", "sourceName": "snooty-docs", "body": "# MongoDB Performance\n\nAs you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\n\nSome users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\n\nPerformance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\n\nIn some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\n\nDatabase profiling can help you to understand what operations are causing degradation.\n\n## Locking Performance\n\nMongoDB uses a locking system to ensure data set consistency. If certain operations are long-running or a queue forms, performance will degrade as requests and operations wait for the lock.\n\nLock-related slowdowns can be intermittent. To see if the lock has been affecting your performance, refer to the locks section and the globalLock section of the `serverStatus` output.\n\nDividing `locks.<type>.timeAcquiringMicros` by `locks.<type>.acquireWaitCount` can give an approximate average wait time for a particular lock mode.\n\n`locks.<type>.deadlockCount` provide the number of times the lock acquisitions encountered deadlocks.\n\nIf `globalLock.currentQueue.total` is consistently high, then there is a chance that a large number of requests are waiting for a lock. This indicates a possible concurrency issue that may be affecting performance.\n\nIf `globalLock.totalTime` is high relative to `uptime`, the database has existed in a lock state for a significant amount of time.\n\nLong queries can result from ineffective use of indexes; non-optimal schema design; poor query structure; system architecture issues; or insufficient RAM resulting in disk reads.\n\n## Number of Connections\n\nIn some cases, the number of connections between the applications and the database can overwhelm the ability of the server to handle requests. The following fields in the `serverStatus` document can provide insight:\n\n- `connections` is a container for the following two fields:\n\n  - `connections.current` the total number of current clients connected to the database instance.\n\n  - `connections.available` the total number of unused connections available for new clients.\n\nIf there are numerous concurrent application requests, the database may have trouble keeping up with demand. If this is the case, increase the capacity of your deployment.\n\nFor write-heavy applications, deploy sharding and add one or more shards to a sharded cluster to distribute load among `mongod` instances.\n\nSpikes in the number of connections can also be the result of application or driver errors. All of the officially supported MongoDB drivers implement connection pooling, which allows clients to use and reuse connections more efficiently. An extremely high number of connections, particularly without corresponding workload, is often indicative of a driver or other configuration error.\n\nUnless constrained by system-wide limits, the maximum number of incoming connections supported by MongoDB is configured with the `maxIncomingConnections` setting. On Unix-based systems, system-wide limits can be modified using the `ulimit` command, or by editing your system's `/etc/sysctl` file. See UNIX `ulimit` Settings for more information.\n\n## Full Time Diagnostic Data Capture\n\nTo help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\n\nFTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\n\nMongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\n\nFTDC data **never** contains any of the following information:\n\n- Samples of queries, query predicates, or query results\n\n- Data sampled from any end-user collection or index\n\n- System or MongoDB user credentials or security certificates\n\nFTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be Personally Identifiable Information (PII). For clusters where these fields are configured with protected, confidential, or PII data, please notify MongoDB engineers before sending FTDC data to coordinate appropriate security measures.\n\nOn Windows, to collect system data such as disk, cpu, and memory, FTDC requires Microsoft access permissions from the following groups:\n\n- Performance Monitor Users\n\n- Performance Log Users\n\nIf the user running `mongod` and `mongos` is not an administrator, add them to these groups to log FTDC data. For more information, see the Microsoft documentation here.\n\nFTDC periodically collects statistics produced by the following commands:\n\n- `serverStatus`\n\n- `replSetGetStatus` (`mongod` only)\n\n- `collStats` for the `local.oplog.rs` collection (`mongod` only)\n\n- `connPoolStats` (`mongos` only)\n\nDepending on the host operating system, the diagnostic data may include one or more of the following utilization statistics:\n\n- CPU utilization\n\n- Memory utilization\n\n- Disk utilization related to performance. FTDC does not include data related to storage capacity.\n\n- Network performance statistics. FTDC only captures metadata and does not capture or inspect any network packets.\n\nIf the `mongod` process runs in a container, FTDC reports utilization statistics from the perspective of the container instead of the host operating system. For example, if a the `mongod` runs in a container that is configured with RAM restrictions, FTDC calculates memory utilization against the container's RAM limit, as opposed to the host operating system's RAM limit.\n\nFTDC collects statistics produced by the following commands on file rotation or startup:\n\n- `getCmdLineOpts`\n\n- `buildInfo`\n\n- `hostInfo`\n\n`mongod` processes store FTDC data files in a `diagnostic.data` directory under the instances `storage.dbPath`. All diagnostic data files are stored under this directory. For example, given a `dbPath` of `/data/db`, the diagnostic data directory would be `/data/db/diagnostic.data`.\n\n`mongos` processes store FTDC data files in a diagnostic directory relative to the `systemLog.path` log path setting. MongoDB truncates the logpath's file extension and concatenates `diagnostic.data` to the remaining name. For example, given a `path` setting of `/var/log/mongodb/mongos.log`, the diagnostic data directory would be `/var/log/mongodb/mongos.diagnostic.data`.\n\nYou can view the FTDC source code on the MongoDB Github Repository. The `ftdc_system_stats_*.ccp` files specifically define any system-specific diagnostic data captured.\n\nFTDC runs with the following defaults:\n\n- Data capture every 1 second\n\n- 200MB maximum `diagnostic.data` folder size.\n\nThese defaults are designed to provide useful data to MongoDB engineers with minimal impact on performance or storage size. These values only require modifications if requested by MongoDB engineers for specific diagnostic purposes.\n\nTo disable FTDC, start up the `mongod` or `mongos` with the `diagnosticDataCollectionEnabled: false` option in the `setParameter` settings of your configuration file:\n\n```yaml\nsetParameter:\n  diagnosticDataCollectionEnabled: false\n```\n\nDisabling FTDC may increase the time or resources required when analyzing or debugging issues with support from MongoDB engineers. For information on MongoDB Support, visit Get Started With MongoDB Support.\n\n", "url": "https://mongodb.com/docs/manual/administration/analyzing-mongodb-performance/", "format": "md", "title": "MongoDB Performance"},
{"updated": "2024-05-20T17:31:07.735Z", "metadata": {"contentType": null, "productName": "MongoDB Server", "tags": ["docs", "manual"], "version": "v7.0 (current)"}, "action": "created", "sourceName": "snooty-docs", "body": "# Backup and Restore Sharded Clusters\n\nThe following tutorials describe backup and restoration for sharded clusters:\n\nTo use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\n\nSharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\n\n- MongoDB Atlas\n\n- MongoDB Cloud Manager\n\n- MongoDB Ops Manager\n\nUse file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\n\nCreate backups using `mongodump` to back up each component in the cluster individually.\n\nLimit the operation of the cluster balancer to provide a window for regular backup operations.\n\nAn outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\n\n", "url": "https://mongodb.com/docs/manual/administration/backup-sharded-clusters/", "format": "md", "title": "Backup and Restore Sharded Clusters"},
{"updated": "2024-05-20T17:31:07.735Z", "metadata": {"contentType": null, "productName": "MongoDB Server", "tags": ["docs", "manual"], "version": "v7.0 (current)"}, "action": "created", "sourceName": "snooty-docs", "body": "# Configuration and Maintenance\n\nThis section describes routine management operations, including updating your MongoDB deployment's configuration.\n\nOutlines common MongoDB configurations and examples of best-practice configurations for common use cases.\n\nUpgrade a MongoDB deployment to a different patch release within the same major release series.\n\nStart, configure, and manage running `mongod` process.\n\nStop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\n\nArchive the current log files and start new ones.\n\n", "url": "https://mongodb.com/docs/manual/administration/configuration-and-maintenance/", "format": "md", "title": "Configuration and Maintenance"},
{"updated": "2024-05-20T17:32:23.500Z", "metadata": {"contentType": "Video", "productName": null, "tags": ["Atlas"], "version": null}, "action": "created", "sourceName": "devcenter", "body": "# The Atlas Search 'cene: Season 1\n\n# The Atlas Search 'cene: Season 1\n\nWelcome to the first season of a video series dedicated to Atlas Search!  This series of videos is designed to guide you through the journey from getting started and understanding the concepts, to advanced techniques.\n\n## What is Atlas Search?\n\n[Atlas Search][1] is an embedded full-text search in MongoDB Atlas that gives you a seamless, scalable experience for building relevance-based app features. Built on Apache Lucene, Atlas Search eliminates the need to run a separate search system alongside your database.\n\nBy integrating the database, search engine, and sync mechanism into a single, unified, and fully managed platform, Atlas Search is the fastest and easiest way to build relevance-based search capabilities directly into applications.\n\n> Hip to the *'cene*\n> \n> The name of this video series comes from a contraction of \"Lucene\",\n> the search engine library leveraged by Atlas. Or it's a short form of \"scene\". \n\n## Episode Guide\n\n### **[Episode 1: What is Atlas Search & Quick Start][2]**\n\nIn this first episode of the Atlas Search 'cene, learn what Atlas Search is, and get a quick start introduction to setting up Atlas Search on your data.  Within a few clicks, you can set up a powerful, full-text search index on your Atlas collection data, and leverage the fast, relevant results to your users queries.\n\n### **[Episode 2: Configuration / Development Environment][3]**\n\nIn order to best leverage Atlas Search, configuring it for your querying needs leads to success. In this episode, learn how Atlas Search maps your documents to its index, and discover the configuration control you have.\n\n### **[Episode 3: Indexing][4]**\n\nWhile Atlas Search automatically indexes your collections content, it does demand attention to the indexing configuration details in order to match users queries appropriately. This episode covers how Atlas Search builds an inverted index, and the options one must consider.\n\n### **[Episode 4: Searching][5]**\n\nAtlas Search provides a rich set of query operators and relevancy controls. This episode covers the common query operators, their relevancy controls, and ends with coverage of the must-have Query Analytics feature.\n\n### **[Episode 5:  Faceting][6]**\n\nFacets produce additional context for search results, providing a list of subsets and counts within. This episode details the faceting options available in Atlas Search.\n\n### **[Episode 6: Advanced Search Topics][7]**\n\nIn this episode, we go through some more advanced search topics including embedded documents, fuzzy search, autocomplete, highlighting, and geospatial.\n\n### **[Episode 7:  Query Analytics][8]**\n\nAre your users finding what they are looking for? Are your top queries returning the best results? This episode covers the important topic of query analytics. If you're using search, you need this!\n\n### **[Episode 8:  Tips & Tricks][9]**\n\nIn this final episode of The Atlas Search 'cene Season 1, useful techniques to introspect query details and see the relevancy scoring computation details. Also shown is how to get facets and search results back in one API call.\n\n  [1]: https://www.mongodb.com/atlas/search\n  [2]: https://www.mongodb.com/developer/videos/what-is-atlas-search-quick-start/\n  [3]: https://www.mongodb.com/developer/videos/atlas-search-configuration-development-environment/\n  [4]: https://www.mongodb.com/developer/videos/mastering-indexing-for-perfect-query-matches/\n  [5]: https://www.mongodb.com/developer/videos/query-operators-relevancy-controls-for-precision-searches/\n  [6]: https://www.mongodb.com/developer/videos/faceting-mastery-unlock-the-full-potential-of-atlas-search-s-contextual-insights/\n  [7]: https://www.mongodb.com/developer/videos/atlas-search-mastery-elevate-your-search-with-fuzzy-geospatial-highlighting-hacks/\n  [8]: https://www.mongodb.com/developer/videos/atlas-search-query-analytics/\n  [9]: https://www.mongodb.com/developer/videos/tips-and-tricks-the-atlas-search-cene-season-1-episode-8/", "url": "https://www.mongodb.com/developer/products/atlas/atlas-search-cene-1", "format": "md", "title": "The Atlas Search 'cene: Season 1"},
{"updated": "2024-05-20T17:32:23.500Z", "metadata": {"contentType": "Tutorial", "productName": null, "tags": ["MongoDB", "JavaScript", "AI", "Node.js"], "version": null}, "action": "created", "sourceName": "devcenter", "body": "# Using MongoDB Atlas Triggers to Summarize Airbnb Reviews with OpenAI\n\nIn the realm of property rentals, reviews play a pivotal role. MongoDB Atlas triggers, combined with the power of OpenAI's models, can help summarize and analyze these reviews in real-time. In this article, we'll explore how to utilize MongoDB Atlas triggers to process Airbnb reviews, yielding concise summaries and relevant tags.\n\nThis article is an additional feature added to the hotels and apartment sentiment search application developed in Leveraging OpenAI and MongoDB Atlas for Improved Search Functionality.\n\n## Introduction\n\nMongoDB Atlas triggers allow users to define functions that execute in real-time in response to database operations. These triggers can be harnessed to enhance data processing and analysis capabilities. In this example, we aim to generate summarized reviews and tags for a sample Airbnb dataset.\n\nOur original data model has each review embedded in the listing document as an array:\n\n```javascript\n\"reviews\":  { \"_id\": \"2663437\", \n\"date\": { \"$date\": \"2012-10-20T04:00:00.000Z\" }, \\\n\"listing_id\": \"664017\",\n \"reviewer_id\": \"633940\", \n\"reviewer_name\": \"Patricia\", \n\"comments\": \"I booked the room at Marinete's apartment for my husband. He was staying in Rio for a week because he was studying Portuguese. He loved the place. Marinete was very helpfull, the room was nice and clean. \\r\\nThe location is perfect. He loved the time there. \\r\\n\\r\\n\" },\n { \"_id\": \"2741592\", \n\"date\": { \"$date\": \"2012-10-28T04:00:00.000Z\" }, \n\"listing_id\": \"664017\",\n \"reviewer_id\": \"3932440\", \n\"reviewer_name\": \"Carolina\", \n\"comments\": \"Es una muy buena anfitriona, preocupada de que te encuentres c\u00f3moda y te sugiere que actividades puedes realizar. Disfrut\u00e9 mucho la estancia durante esos d\u00edas, el sector es central y seguro.\" }, ... ]\n```\n\n## Prerequisites\n- App Services application (e.g., application-0). Ensure linkage to the cluster with the Airbnb data.\n- OpenAI account with API access. \n\n![Open AI Key\n\n### Secrets and Values\n\n1. Navigate to your App Services application.\n2. Under \"Values,\" create a secret named `openAIKey` with your OPEN AI API key.\n\n3. Create a linked value named OpenAIKey and link to the secret.\n\n## The trigger code\n\nThe provided trigger listens for changes in the sample_airbnb.listingsAndReviews collection. Upon detecting a new review, it samples up to 50 reviews, sends them to OpenAI's API for summarization, and updates the original document with the summarized content and tags.\n\nPlease notice that the trigger reacts to updates that were marked with `\"process\" : false` flag. This field indicates that there were no summary created for this batch of reviews yet.\n\nExample of a review update operation that will fire this trigger:\n```javascript\nlistingsAndReviews.updateOne({\"_id\" : \"1129303\"}, { $push : { \"reviews\" : new_review } , $set : { \"process\" : false\" }});\n```\n\n### Sample reviews function\nTo prevent overloading the API with a large number of reviews, a function sampleReviews is defined to randomly sample up to 50 reviews:\n\n```javscript\nfunction sampleReviews(reviews) {\n    if (reviews.length <= 50) {\n        return reviews;\n    }\n\n    const sampledReviews = ];\n    const seenIndices = new Set();\n\n    while (sampledReviews.length < 50) {\n        const randomIndex = Math.floor(Math.random() * reviews.length);\n        if (!seenIndices.has(randomIndex)) {\n            seenIndices.add(randomIndex);\n            sampledReviews.push(reviews[randomIndex]);\n        }\n    }\n\n    return sampledReviews;\n}\n```\n\n### Main trigger logic\n\nThe main trigger logic is invoked when an update change event is detected with a `\"process\" : false` field.\n```javascript\nexports = async function(changeEvent) {\n  // A Database Trigger will always call a function with a changeEvent.\n  // Documentation on ChangeEvents: https://www.mongodb.com/docs/manual/reference/change-events\n\n  // This sample function will listen for events and replicate them to a collection in a different Database\nfunction sampleReviews(reviews) {\n// Logic above...\n   if (reviews.length <= 50) {\n        return reviews;\n    }\n    const sampledReviews = [];\n    const seenIndices = new Set();\n\n    while (sampledReviews.length < 50) {\n        const randomIndex = Math.floor(Math.random() * reviews.length);\n        if (!seenIndices.has(randomIndex)) {\n            seenIndices.add(randomIndex);\n            sampledReviews.push(reviews[randomIndex]);\n        }\n    }\n\n    return sampledReviews;\n}\n\n  // Access the _id of the changed document:\n  const docId = changeEvent.documentKey._id;\n  const doc= changeEvent.fullDocument;\n  \n\n  // Get the MongoDB service you want to use (see \"Linked Data Sources\" tab)\n  const serviceName = \"mongodb-atlas\";\n  const databaseName = \"sample_airbnb\";\n  const collection = context.services.get(serviceName).db(databaseName).collection(changeEvent.ns.coll);\n\n // This function is the endpoint's request handler. \n    // URL to make the request to the OpenAI API.\n    const url = 'https://api.openai.com/v1/chat/completions';\n\n    // Fetch the OpenAI key stored in the context values.\n    const openai_key = context.values.get(\"openAIKey\");\n\n    const reviews = doc.reviews.map((review) => {return {\"comments\" : review.comments}});\n    \n    const sampledReviews= sampleReviews(reviews);\n\n    // Prepare the request string for the OpenAI API.\n    const reqString = `Summerize the reviews provided here: ${JSON.stringify(sampledReviews)} | instructions example:\\n\\n [{\"comment\" : \"Very Good bed\"} ,{\"comment\" : \"Very bad smell\"} ] \\nOutput: {\"overall_review\": \"Overall good beds and bad smell\" , \"neg_tags\" : [\"bad smell\"], pos_tags : [\"good bed\"]}. No explanation. No 'Output:' string in response. Valid JSON. `;\n    console.log(`reqString: ${reqString}`);\n\n    // Call OpenAI API to get the response.\n    \n    let resp = await context.http.post({\n        url: url,\n        headers: {\n            'Authorization': [`Bearer ${openai_key}`],\n            'Content-Type': ['application/json']\n        },\n        body: JSON.stringify({\n            model: \"gpt-4\",\n            temperature: 0,\n            messages: [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"Output json generator follow only provided example on the current reviews\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": reqString\n                }\n            ]\n        })\n    });\n\n    // Parse the JSON response\n    let responseData = JSON.parse(resp.body.text());\n\n    // Check the response status.\n    if(resp.statusCode === 200) {\n        console.log(\"Successfully received code.\");\n        console.log(JSON.stringify(responseData));\n\n        const code = responseData.choices[0].message.content;\n        // Get the required data to be added into the document\n        const updateDoc = JSON.parse(code)\n        // Set a flag that this document does not need further re-processing \n        updateDoc.process = true\n        await collection.updateOne({_id : docId}, {$set : updateDoc});\n      \n\n    } else {\n        console.error(\"Failed to generate filter JSON.\");\n        console.log(JSON.stringify(responseData));\n        return {};\n    }\n};\n```\n\nKey steps include:\n\n- API request preparation: Reviews from the changed document are sampled and prepared into a request string for the OpenAI API. The format and instructions are tailored to ensure the API returns a valid JSON with summarized content and tags.\n- API interaction: Using the context.http.post method, the trigger sends the prepared data to the OpenAI API.\n- Updating the original document: Upon a successful response from the API, the trigger updates the original document with the summarized content, negative tags (neg_tags), positive tags (pos_tags), and a process flag set to true.\n\nHere is a sample result that is added to the processed listing document:\n```\n\"process\": true, \n\"overall_review\": \"Overall, guests had a positive experience at Marinete's apartment. They praised the location, cleanliness, and hospitality. However, some guests mentioned issues with the dog and language barrier.\",\n\"neg_tags\": [ \"language barrier\", \"dog issues\" ], \n\"pos_tags\": [ \"great location\", \"cleanliness\", \"hospitality\" ]\n```\n\nOnce the data is added to our documents, providing this information in our VUE application is as simple as adding this HTML template:\n\n```html\n\n     Overall Review (ai based) : {{ listing.overall_review }}\n      \n          {{tag}}\n      \n      \n        {{tag}}\n      \n  \n```\n\n## Conclusion\nBy integrating MongoDB Atlas triggers with OpenAI's powerful models, we can efficiently process and analyze large volumes of reviews in real-time. This setup not only provides concise summaries of reviews but also categorizes them into positive and negative tags, offering valuable insights to property hosts and potential renters.\n\nQuestions? Comments? Let\u2019s continue the conversation over in our [community forums.", "url": "https://www.mongodb.com/developer/products/mongodb/atlas-open-ai-review-summary", "format": "md", "title": "Using MongoDB Atlas Triggers to Summarize Airbnb Reviews with OpenAI"},
{"updated": "2024-05-20T17:32:23.500Z", "metadata": {"contentType": "Tutorial", "productName": null, "tags": ["MongoDB", "JavaScript", "Java", "Python", "AWS", "AI"], "version": null}, "action": "created", "sourceName": "devcenter", "body": "# Getting Started with MongoDB and AWS Codewhisperer\n\n**Introduction**\n----------------\n\nAmazon CodeWhisperer is trained on billions of lines of code and can generate code suggestions \u2014 ranging from snippets to full functions \u2014 in real-time, based on your comments and existing code. AI code assistants have revolutionized developers\u2019 coding experience, but what sets Amazon CodeWhisperer apart is that MongoDB has collaborated with the AWS Data Science team, enhancing its capabilities!\n\nAt MongoDB, we are always looking to enhance the developer experience, and we've fine-tuned the CodeWhisperer Foundational Models to deliver top-notch code suggestions \u2014 trained on, and tailored for, MongoDB. This gives developers of all levels the best possible experience when using CodeWhisperer for MongoDB functions. \n\nThis tutorial will help you get CodeWhisperer up and running in VS Code, but CodeWhisperer also works with a number of other IDEs, including IntelliJ IDEA, AWS Cloud9, AWS Lambda console, JupyterLab, and Amazon SageMaker Studio. On the [Amazon CodeWhisperer site][1], you can find tutorials that demonstrate how to set up CodeWhisperer on different IDEs, as well as other documentation.\n\n*Note:* CodeWhisperer allows users to start without an AWS account because usually, creating an AWS account requires a credit card. Currently, CodeWhisperer is free for individual users. So it\u2019s super easy to get up and running.\n\n**Installing CodeWhisperer for VS Code** \n\nCodeWhisperer doesn\u2019t have its own VS Code extension. It is part of a larger extension for AWS services called AWS Toolkit. AWS Toolkit is available in the VS Code extensions store. \n\n 1. Open VS Code and navigate to the extensions store (bottom icon on the left panel).\n 2. Search for CodeWhisperer and it will show up as part of the AWS Toolkit.\n![Searching for the AWS ToolKit Extension][2]\n 3. Once found, hit Install. Next, you\u2019ll see the full AWS Toolkit\n    Listing\n![The AWS Toolkit full listing][3]\n 4. Once installed, you\u2019ll need to authorize CodeWhisperer via a Builder\n    ID to connect to your AWS developer account (or set up a new account\n    if you don\u2019t already have one).\n![Authorise CodeWhisperer][4]\n\n**Using CodeWhisperer**\n-----------------------\n\nNavigating code suggestions \n\n![CodeWhisperer Running][5]\n\nWith CodeWhisperer installed and running, as you enter your prompt or code, CodeWhisperer will offer inline code suggestions. If you want to keep the suggestion, use **TAB** to accept it. CodeWhisperer may provide multiple suggestions to choose from depending on your use case. To navigate between suggestions, use the left and right arrow keys to view them, and **TAB** to accept.\n\nIf you don\u2019t like the suggestions you see, keep typing (or hit **ESC**). The suggestions will disappear, and CodeWhisperer will generate new ones at a later point based on the additional context.\n\n**Requesting suggestions manually**\n\nYou can request suggestions at any time. Use **Option-C** on Mac or **ALT-C** on Windows. After you receive suggestions, use **TAB** to accept and arrow keys to navigate.\n\n**Getting the best recommendations**\n\nFor best results, follow these practices.\n\n - Give CodeWhisperer something to work with. The more code your file contains, the more context CodeWhisperer has for generating recommendations.\n - Write descriptive comments in natural language \u2014 for example\n```\n// Take a JSON document as a String and store it in MongoDB returning the _id\n```\nOr\n```\n//Insert a document in a collection with a given _id and a discountLevel\n```\n - Specify the libraries you prefer at the start of your file by using import statements.\n```\n// This Java class works with MongoDB sync driver.\n// This class implements Connection to MongoDB and CRUD methods.\n```\n - Use descriptive names for variables and functions\n - Break down complex tasks into simpler tasks\n\n**Provide feedback**\n----------------\n\nAs with all generative AI tools, they are forever learning and forever expanding their foundational knowledge base, and MongoDB is looking for feedback. If you are using Amazon CodeWhisperer in your MongoDB development, we\u2019d love to hear from you. \n\nWe\u2019ve created a special \u201ccodewhisperer\u201d tag on our [Developer Forums][6], and if you tag any post with this, it will be visible to our CodeWhisperer project team and we will get right on it to help and provide feedback. If you want to see what others are doing with CodeWhisperer on our forums, the [tag search link][7] will jump you straight into all the action. \n\nWe can\u2019t wait to see your thoughts and impressions of MongoDB and Amazon CodeWhisperer together. \n\n  [1]: https://aws.amazon.com/codewhisperer/resources/#Getting_started\n  [2]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/blt1bfd28a846063ae9/65481ef6e965d6040a3dcc37/CW_1.png\n  [3]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/bltde40d5ae1b9dd8dd/65481ef615630d040a4b2588/CW_2.png\n  [4]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/blt636bb8d307bebcee/65481ef6a6e009040a740b86/CW_3.png\n  [5]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/bltf1e0ebeea2089e6a/65481ef6077aca040a5349da/CW_4.png\n  [6]: https://www.mongodb.com/community/forums/\n  [7]: https://www.mongodb.com/community/forums/tag/codewhisperer", "url": "https://www.mongodb.com/developer/products/mongodb/getting-started-with-mongodb-and-codewhisperer", "format": "md", "title": "Getting Started with MongoDB and AWS Codewhisperer"},
{"updated": "2024-05-20T17:32:23.500Z", "metadata": {"contentType": "Code Example", "productName": null, "tags": ["Java", "Spring"], "version": null}, "action": "created", "sourceName": "devcenter", "body": "# REST APIs with Java, Spring Boot, and MongoDB\n\n## GitHub repository\n\nIf you want to write REST APIs in Java at the speed of light, I have what you need. I wrote this template to get you started. I have tried to solve as many problems as possible in it.\n\nSo if you want to start writing REST APIs in Java, clone this project, and you will be up to speed in no time.\n\n```shell\ngit clone https://github.com/mongodb-developer/java-spring-boot-mongodb-starter\n```\n\nThat\u2019s all folks! All you need is in this repository. Below I will explain a few of the features and details about this template, but feel free to skip what is not necessary for your understanding.\n\n## README\n\nAll the extra information and commands you need to get this project going are in the `README.md` file which you can read in GitHub.\n\n## Spring and MongoDB configuration\n\nThe configuration can be found in the MongoDBConfiguration.java class.\n\n```java\npackage com.mongodb.starter;\n\nimport ...]\n\nimport static org.bson.codecs.configuration.CodecRegistries.fromProviders;\nimport static org.bson.codecs.configuration.CodecRegistries.fromRegistries;\n\n@Configuration\npublic class MongoDBConfiguration {\n\n    @Value(\"${spring.data.mongodb.uri}\")\n    private String connectionString;\n\n    @Bean\n    public MongoClient mongoClient() {\n        CodecRegistry pojoCodecRegistry = fromProviders(PojoCodecProvider.builder().automatic(true).build());\n        CodecRegistry codecRegistry = fromRegistries(MongoClientSettings.getDefaultCodecRegistry(), pojoCodecRegistry);\n        return MongoClients.create(MongoClientSettings.builder()\n                                                      .applyConnectionString(new ConnectionString(connectionString))\n                                                      .codecRegistry(codecRegistry)\n                                                      .build());\n    }\n\n}\n```\n\nThe important section here is the MongoDB configuration, of course. Firstly, you will notice the connection string is automatically retrieved from the `application.properties` file, and secondly, you will notice the configuration of the `MongoClient` bean.\n\nA `Codec` is the interface that abstracts the processes of decoding a BSON value into a Java object and encoding a Java object into a BSON value.\n\nA `CodecRegistry` contains a set of `Codec` instances that are accessed according to the Java classes that they encode from and decode to.\n\nThe MongoDB driver is capable of encoding and decoding BSON for us, so we do not have to take care of this anymore. All the configuration we need for this project to run is here and nowhere else.\n\nYou can read [the driver documentation if you want to know more about this topic.\n\n## Multi-document ACID transactions\n\nJust for the sake of it, I also used multi-document ACID transactions in a few methods where it could potentially make sense to use ACID transactions. You can check all the code in the `MongoDBPersonRepository` class.\n\nHere is an example:\n\n```java\nprivate static final TransactionOptions txnOptions = TransactionOptions.builder()\n    .readPreference(ReadPreference.primary())\n    .readConcern(ReadConcern.MAJORITY)\n    .writeConcern(WriteConcern.MAJORITY)\n    .build();\n\n@Override\npublic List saveAll(List personEntities) {\n    try (ClientSession clientSession = client.startSession()) {\n        return clientSession.withTransaction(() -> {\n            personEntities.forEach(p -> p.setId(new ObjectId()));\n            personCollection.insertMany(clientSession, personEntities);\n            return personEntities;\n        }, txnOptions);\n    }\n}\n```\n\nAs you can see, I\u2019m using an auto-closeable try-with-resources which will automatically close the client session at the end. This helps me to keep the code clean and simple.\n\nSome of you may argue that it is actually too simple because transactions (and write operations, in general) can throw exceptions, and I\u2019m not handling any of them here\u2026 You are absolutely right and this is an excellent transition to the next part of this article.\n\n## Exception management\n\nTransactions in MongoDB can raise exceptions for various reasons, and I don\u2019t want to go into the details too much here, but since MongoDB 3.6, any write operation that fails can be automatically retried once. And the transactions are no different. See the documentation for retryWrites.\n\nIf retryable writes are disabled or if a write operation fails twice, then MongoDB will send a MongoException (extends RuntimeException) which should be handled properly.\n\nLuckily, Spring provides the annotation `ExceptionHandler` to help us do that. See the code in my controller `PersonController`. Of course, you will need to adapt and enhance this in your real project, but you have the main idea here.\n\n```java\n@ExceptionHandler(RuntimeException.class)\npublic final ResponseEntity handleAllExceptions(RuntimeException e) {\n    logger.error(\"Internal server error.\", e);\n    return new ResponseEntity<>(e, HttpStatus.INTERNAL_SERVER_ERROR);\n}\n```\n\n## Aggregation pipeline\n\nMongoDB's aggregation pipeline is a very powerful and efficient way to run your complex queries as close as possible to your data for maximum efficiency. Using it can ease the computational load on your application.\n\nJust to give you a small example, I implemented the `/api/persons/averageAge` route to show you how I can retrieve the average age of the persons in my collection.\n\n```java\n@Override\npublic double getAverageAge() {\n    List pipeline = List.of(group(new BsonNull(), avg(\"averageAge\", \"$age\")), project(excludeId()));\n    return personCollection.aggregate(pipeline, AverageAgeDTO.class).first().averageAge();\n}\n```\n\nAlso, you can note here that I\u2019m using the `personCollection` which was initially instantiated like this:\n\n```java\nprivate MongoCollection personCollection;\n\n@PostConstruct\nvoid init() {\n    personCollection = client.getDatabase(\"test\").getCollection(\"persons\", PersonEntity.class);\n}\n```\n\nNormally, my personCollection should encode and decode `PersonEntity` object only, but you can overwrite the type of object your collection is manipulating to return something different \u2014 in my case, `AverageAgeDTO.class` as I\u2019m not expecting a `PersonEntity` class here but a POJO that contains only the average age of my \"persons\".\n\n## Swagger\n\nSwagger is the tool you need to document your REST APIs. You have nothing to do \u2014 the configuration is completely automated. Just run the server and navigate to http://localhost:8080/swagger-ui.html. the interface will be waiting for you.\n\n for more information.\n\n## Nyan Cat\n\nYes, there is a Nyan Cat section in this post. Nyan Cat is love, and you need some Nyan Cat in your projects. :-)\n\nDid you know that you can replace the Spring Boot logo in the logs with pretty much anything you want?\n\n and the \"Epic\" font for each project name. It's easier to identify which log file I am currently reading.\n\n## Conclusion\n\nI hope you like my template, and I hope I will help you be more productive with MongoDB and the Java stack.\n\nIf you see something which can be improved, please feel free to open a GitHub issue or directly submit a pull request. They are very welcome. :-)\n\nIf you are new to MongoDB Atlas, give our Quick Start post a try to get up to speed with MongoDB Atlas in no time.\n\n  [1]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/blt876f3404c57aa244/65388189377588ba166497b0/swaggerui.png\n  [2]: https://images.contentstack.io/v3/assets/blt39790b633ee0d5a7/bltf2f06ba5af19464d/65388188d31953242b0dbc6f/nyancat.png", "url": "https://www.mongodb.com/developer/code-examples/java/rest-apis-java-spring-boot", "format": "md", "title": "REST APIs with Java, Spring Boot, and MongoDB"},
{"updated": "2024-05-20T17:32:23.500Z", "metadata": {"contentType": "News & Announcements", "productName": null, "tags": ["Swift", "MongoDB"], "version": null}, "action": "created", "sourceName": "devcenter", "body": "# Halting Development on MongoDB Swift Driver\n\nMongoDB is halting development on our server-side Swift driver. We remain excited about Swift and will continue our development of our mobile Swift SDK.\n\nWe released our server-side Swift driver in 2020 as an open source project and are incredibly proud of the work that our engineering team has contributed to the Swift community over the last four years. Unfortunately, today we are announcing our decision to stop development of the MongoDB server-side Swift driver. We understand that this news may come as a disappointment to the community of current users.\n\nThere are still ways to use MongoDB with Swift:\n\n - Use the MongoDB driver with server-side Swift applications as is \n - Use the MongoDB C Driver directly in your server-side Swift projects\n - Usage of another community Swift driver, mongokitten\n\nCommunity members and developers are welcome to fork our existing driver and add features as you see fit - the Swift driver is under the Apache 2.0 license and source code is available on GitHub. For those developing client/mobile applications, MongoDB offers the Realm Swift SDK with real time sync to MongoDB Atlas.\n\nWe would like to take this opportunity to express our heartfelt appreciation for the enthusiastic support that the Swift community has shown for MongoDB. Your loyalty and feedback have been invaluable to us throughout our journey, and we hope to resume development on the server-side Swift driver in the future.", "url": "https://www.mongodb.com/developer/languages/swift/halting-development-on-swift-driver", "format": "md", "title": "Halting Development on MongoDB Swift Driver"}
]